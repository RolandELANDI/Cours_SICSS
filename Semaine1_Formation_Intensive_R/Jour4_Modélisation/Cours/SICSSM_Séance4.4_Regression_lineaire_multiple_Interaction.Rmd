---
title: 'Séance 4.4: Regression linéaire multiple - fin'
subtitle: "Interprétation - violations des hypothèses - extension"
author: "Visseho Adjiwanou, PhD."
institute: "SICSS - Montréal"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  beamer_presentation:
    colortheme: beaver
    fonttheme: structurebold
    theme: AnnArbor
  slidy_presentation: default
  ioslides_presentation: default
---


## Plan de présentation

- Rappel
- Interprétation des résultats
- Violation des hypothèses
  - Interaction
  - Paramètres changeant: Interaction
  - Variables importantes omises
- Extension
  - Test d'hypothèses

Rappel
======================================================

## Spécification

$$ Y_i = \alpha + \beta_1 X_{1i} +  \beta_2 X_{2i} + ...+\beta_k X_{ki} +\epsilon_i$$
Où $\epsilon_i$ suit une loi normale de moyenne 0 et de variance $\sigma^2$. 
- On a k indépdnantes variables pour n observations {($Y_1$, $X_{11}$, $X_{12}$, ..., $X_{1k}$), ..., ($Y_n$, $X_{n1}$, $X_{n2}$, ..., $X_{nk}$)}.

Exemple:
  - Y peut être le poids à la naissance
  - X1 l'age de la mère à la naissance de l'enfant
  - X2 le sexe de l'enfant

## Spécification

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/matrice_regression.png)


Estimation des paramètres
======================================================

## Hypothèses

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/hypotheses_regression.png)


## Estimation des paramètres

- Les paramètres inconnus:
  - k (beta) + 1 (alpha) paramètres
  - $\sigma^2$

- On démontre que :

$\beta^* = (X^{'}X)^{-1}(X^{'}Y)$

Variance-covariance de $Varcov(\beta^*) = \sigma^2(X^{'}X)^{-1}$

Mais encore une fois, $\sigma^2$ n'est pas connu. Il est remplacé par:

$s^2 = e^{'}e/(T-k)$

avec (e = Y-Y')


Interprétation
======================================================


## Résultats importants et interprétation

- Même si on ne reporte pas l'ensemble des résultats d'une régression, voici les principaux résultats et leur interprétation.  

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/fisher1.png)
## Résultats importants et interprétation

1. Qualité du modèle
- Model SS : Somme des carrés du modèle  = $\sum({Y_i^*} - \bar{Y})^2$
- REsidual SS : Somme des carrés résiduelles = $\sum({Y_i} - {Y_i^*})^2$ = $\sum[{Y_i} - ({\alpha + \beta*X_i}]^2$
- Total SS : Somme des carrées totale = $\sum(Y_i - \bar{Y})^2$

Un modèle sera bon si la somme des carrés du modèle se rapproche de la somme des carrés total

- Les df sont les degrés de liberté. Ils permettent de corriger les modèles selon le nombre de variables dépendantes
  - model df = nombre de variables indépendantes (sauf la constante)
  - residual df = taille de l'échantillon  - nombre de variables dépendantes y compris le terme constant
  - total df = model df + residual df
  
- Variances expliquées: en divisant les sommes des carrés par les df, on obtient les variances:
  - Model MS (mean square): Variance expliquée par le modèle
  - Residual Ms : variance résiduelle
  - Total MS: Variance totale 

A partir de ces variances, on calcule le R carré qui vaut:

$$R^2 = (Model SS) / (Total SS) = 1 - (Residual SS)/(Total SS)$$

Les autres parties du tableau permettent de tester quelques hypothèses dont:
- Est-ce que le modèle dans sa globalité est significatif?
- Est-ce qu'une variable est significative
- Et bien plus...

Test d'hypothèses en régression linéaire classique
==============================================================

## Introduction

Passons maintenant au problème de l’utilisation du modèle de régression pour tester des hypothèses. Le type d'hypothèse le plus couramment testé avec l'aide du modèle de régression est qu'il n'y a pas de relation entre la variable explicative X et la variable dépendante Y.

## Test pour une variable explicative: test de Student

En supposant que toutes les hypothèses des modèles de régression linéaire sont valides:

 - L'équation de regression  $Y_i = \alpha + \beta_1 X_{1i} +  \beta_2 X_{2i} + ...+\beta_k X_{ki} +\epsilon_i$
 - Ou: $E(Y_i) = \alpha + \beta_1 X_{1i} +  \beta_2 X_{2i} + ...+\beta_k X_{ki}$

- Tester que $\beta_i = 0$ signifie que
  - Il n'y a pas de relation entre X et Y
  - La valeur moyenne de $Y_i$ ne dépend pas linéairement de $X_i$
  - La droite de régression de population est horizontale (en régression linéaire simple)


## Test pour une variable explicative: test de Student

- Ce test est basé sur la variance de $\beta_i$
- En cas de régression multiple, le calcul de cette variance est compliqué et n'est pas présenté ici.
- En cas de MRL, nous avons vu que:

  - Variance de la pente : $Var(\beta^*) = \frac{\sigma_\epsilon^2}{\sum(X_i - \bar{X})^2}$
  - Variance de l'intercept: $Var(\alpha^*) = \sigma_\epsilon^2[\frac{1}{n} + \frac{\bar{X^2}}{\sum(X_i - \bar{X})^2}]$

- Mais comme $\sigma^2$ est inconnu, il est remplacé par son estimateur (s). Finalement, on a:


  - Estimateur de la variance de la pente: $s^2_{\beta^*} = \hat{Var(\beta^*)} = \frac{s^2}{\sum(X_i - \bar{X})^2}$
  - Estimateur de la variance de l'intercept: $s^2_{\alpha^*} = s^2[\frac{1}{n} + \frac{\bar{X^2}}{\sum(X_i - \bar{X})^2}]$

## Test pour une variable explicative: test de Student

Comment faire le test?

1. Énoncez l'hypothèse nulle ($\beta_1 = \mu_1$)
2. Choisissez le niveau de signification ($\alpha$, 0.1%, 1%, 5%)
3. Comparer $\beta^*_1$ à $\mu_1$
  - Si $\beta^*_1 = \mu_1$, pas besoin de tester, sinon testez
4. Type de test: test bilatéral ou test unilatéral
  - Toujours privilégier le test bilatéral
  - Hypothèse forte derrière le test unilatéral
5. Calculer les statistiques sous l'hypothèse nulle
  - t of Student (z normal dans l'exemple précédent)
6. Décision: Comparez le t calculé au t qui vous est donné par la table de distribution au niveau de signification $\alpha$

## Test pour une variable explicative: test de Student

- Sous l'hypothèse nulle:

$$t^* = \frac{\beta^*_1 - \mu_1}{s_{\beta_1^*}} \sim \text{une loi de Student avec n - (k+1) degrés de liberté}$$
  - n est la taille de l'évhantillon
  
  - k est le nombre de variables indépendantes (excluant l'intercept)

- Décision:

  - Si |t*| > t(lu), rejeter l'hypothèse nulle
  - Si |t*| < (t(lu), ne rejeter pas l'hypothèse nulle

## Exemple: Déterminant du nombre d'enfants

On estime le modèle:

$$Parite_i = \alpha + \beta_1*urbain_i + \beta_2*sans-education_i + \beta_3*college_i + \beta_4*catholique_i + $$ 

$$\beta_5*protestant_i + \beta_6*animiste_i + \beta_7*sans-religion_i + \beta_8*age_i +\epsilon_i$$

- Où $Parite_i$ est le nombre d'enfants vivants de la femme i.

## Exemple: Déterminant du nombre d'enfants

Le tableau suivant preesente les résultats de cette régression

Variables                      Coefficients             Erreur standard
------------------------------ ------------------------ ------------------------
Constant                       -3.855                   0.092
Urbain                         -0.634                   0.057
Sans-education                  0.137                   0.074
College                        -0.738                   0.097
Catholique                     -0.095                   0.051
Protestant                      0.074                   0.086
Animiste                        0.040                   0.067
Sans-religion                   0.138                   0.111
Age                             0.261                   0.002

- Référence?
- N = 6444


## Test d'une variable continue

- Testez que $\beta_{age} = 0$

- Valeur de beta estimé: $\beta^*_{age} = 0,261 \neq 0$,  test possible pour voir si l'âge n'est pas lié à la parité

- t calculé: $t^* = \frac{(\beta^*_{age} - 0)}{s^*_{\beta^*_{age}}}$ = (0.261-0)/0.002 = 130.5

- le t calculé: $t^*$ suit une loi de Student avec (6444 - (8 + 1)) = 6435 degrés de liberté

- Considérons le seuil de significativité $\alpha = 1\%$
  - t(lu) = 2,58

- Décision

  - le t calculé $t^* > t(lu)$, on rejette l'hypothèse nulle

- Conclusion: l'âge a un effet significatif sur la parité

## Test d'une variable dichotomique

- Comparer deux groupes distincts

  - Test que $\beta_{catholique} = 0$
  - Dans ce cas précis, vérifiez si les femmes catholiques ont une parité sensiblement différente de celle des femmes musulmanes.

- Le test est identique à celui effectué précédemment
  - Hypothèse nulle: $H_0: \beta_{catholique} = 0$
  - t calculé : $t^* = \frac{(\beta^*_{catholique} - 0)}{s_{\beta^*_{catholique}}}$ = (-0,095 - 0)/0,051 = -1.863

- Décision:
    - Seuil $\alpha = 1\%$ ==> t(lu) = 2,58, conclusion?
    - Seuil $\alpha = 5\%$ ==> t(lu) = 1,96, conclusion?
    - Seuil $\alpha = 10\%$ ==> t(lu) = 1,64, conclusion?

## Intervalle de confiance

- On parle d'intervalle de confiance en cas de test bilatéral
- Cet intervalle est donné par défaut à 95%, le complément à 1 de $\alpha$
- L'intervalle de confiance peut également être utilisé pour le test d'hypothèse
  - Les valeurs en dehors de l'intervalle sont significativement différentes de $\beta^*$
  - Les valeurs à l'intérieur de l'intervalle ne sont pas significativement différentes de $\beta^*$

Conclusion: Une variable a un effet significatif si l'intervalle de confiance de ses estimations ne contient pas 0.

## Intervalle de confiance

- La formule de l'intervalle de confiance est:

$$IC = \beta^*_s ± t_{\alpha}*s_{\beta^*}$$
$$[\beta^*_s - t_{\alpha}*s_{\beta^*}, \beta^*_s + t_{\alpha}*s_{\beta^*}]$$
- Exemple: intervalle de confiance de $\beta^*_{age}$

  - [0.261 - 1.96(0.002), 0.261 + 1.96(0.002)]
  - [0.257, 0.265]
  
  
Test pour plus d'une variable explicative
=========================================================

## Introduction

Utilisé pour tester plusieurs hypothèses à la fois, à la différence du test t, qui ne portait que sur une hypothèse.

Considérons:

- L'équation de regression  $Y_i = \alpha + \beta_1 X_{1i} +  \beta_2 X_{2i} + ...+\beta_k X_{ki} +\epsilon_i$
 
- L’un des tests les plus simples est l’égalité entre deux paramètres:
  - Hypothèse nulle: $H_0: \beta_1 = \beta_2$; 
  - Hypothèse alternative: $H_A: \beta_1 \neq \beta_2$

## Introduction

- Ou pour tester: 
  - Hypothèse nulle: $H_0: \beta_1 = 1$ et  $\beta_2 = 2$ 
  - Hypothèse alternative: $H_A: H_0$ n'est pas vrai). 
  - Ce qui est différent de deux tests t
    -t test 1: $H_0: \beta_1 = 1$ et $H_A: \beta_1 \neq 1$
    -t test 2: $H_0: \beta_2 = 2$ et $H_A: \beta_2 \neq 2$

## F test: formulation

- Le test de ces hypothèses utilise le test F (Fischer) basé sur deux modèles:

1. Le modèle sans restriction ou sans contrainte

  - Contient tous les (K + 1) paramètres  à estimer
  
2. Le modèle restreint ou contraint

  - Prendre en compte les contraintes imposées au modèle:
    - Contraintes: $(\beta_1 = \beta_2)$ ou $(\beta_1 = 1, \beta_2 = 2)$

  - Si c est le nombre de contraintes le modèle restreint aura K + 1 - c paramètres
  
## Exemples

Cas 1: $H_0: \beta_1 = \beta_2$

- c = 1

- Modèle non contraint
  - UM: $Y_i = \alpha + \beta_1 X_{1i} +  \beta_2 X_{2i} + ...+\beta_k X_{ki} +\epsilon_i$
- Modèle contraint
  - RM: $Y_i = \alpha + \beta_1 X_{1i} +  \beta_1 X_{2i} + ...+\beta_k X_{ki} +\epsilon_i$
  - RM: $Y_i = \alpha + \beta_1 (X_{1i} + X_{2i}) + ...+\beta_k X_{ki} +\epsilon_i$
  - RM: $Y_i = \alpha + \beta_1 Z_{i} + ...+\beta_k X_{ki} +\epsilon_i$
    - Avec $Z_{i} = (X_{1i} + X_{2i})$
    
## Exemples

Cas 2: $H_0: \beta_1 = 1$ et $\beta_2 = 2$

- c = 2

- Modèle non contraint
  - UM: $Y_i = \alpha + \beta_1 X_{1i} +  \beta_2 X_{2i} + ...+\beta_k X_{ki} +\epsilon_i$
- Modèle contraint
  - RM: $Y_i = \alpha + 1 X_{1i} +  2 X_{2i} + ...+\beta_k X_{ki} +\epsilon_i$
  - RM: $Y_i -  1 X_{1i} - 2X_{2i} = \alpha + ...+\beta_k X_{ki} +\epsilon_i$
  - RM: $T_i = \alpha + \beta_3 X_{3i} + ...+\beta_k X_{ki} +\epsilon_i$
    - Avec $T_{i} = Y_i -  1 X_{1i} - 2X_{2i}$
    
## F test

- Calculer la somme des carrés des résidus (SSR) de chaque modèle
- Calculer la statistique F

$$F^* = \frac{[SSR(RM) - SSR(UM)]/c}{SSR(UM)/(n-(k+1))} \sim Fischer_{c, n-(k+1)}$$

- Accéder à la valeur critique de F à partir de la table Fischer
    
- Règle de décision
  - Si $F* > F(lu)$, rejeter l'hypothèse nulle
  - Si $F* < F(lu)$, ne pas rejeter l'hypothèse nulle


## Exemple

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/fisher1.png)


## Exemple 1

$$Parite_i = \alpha + \beta_1*urbain_i + \beta_2*sans-education_i + \beta_3*college_i + \beta_4*catholique_i + $$ 


$$\beta_5*protestant_i + \beta_6*animiste_i + \beta_7*sans-religion_i + \beta_8*age_i +\epsilon_i$$

- Hypothèse nulle: $H_0: \beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = \beta_6 = \beta_7 = \beta_8 = 0$
- Hypothèse alternative: $H_A$?

- Résultat:
  - SSR(UM) = 59968.90 
  - SSR(RM) = 61414.84 (RM: $Parite_i = \alpha$ 
  - C=?

## Exemple 1

$$F^* = \frac{[61414.84 - 59968.90)]/8}{59968.90/(6444 - 9)} = 19.39$$

- F(lu) = $F_{8, 6435} = 1.94$ pour $\alpha = 0.05$

- Décision:
  - Comme $F^* > F(lu)$, on rejette l'hypothèse nulle
  
- Conclusion: Les 8 variables indépendantes ont toutes un effet significatif sur la parité.

## Exemple 2


$$Parite_i = \alpha + \beta_1*urbain_i + \beta_2*primaire_i + \beta_3*college_i + \beta_4*catholique_i + ... + \beta_8*age_i +\epsilon_i$$


- Hypothèse nulle: $H_0: \beta_2 = \beta_3$

  - (il n'existe pas de différence entre l’effet de niveau d’enseignement primaire et l’effet de niveau d’enseignement secondaire)

- Hypothèse alternative: $H_A : \beta_2 \neq \beta_3$

- RM: $Parite_i = \alpha + \beta_1*urbain_i + \beta_2(primaire_i + college_i) + \beta_4*catholique_i +...+ \beta_8*age_i +\epsilon_i$

- Cacluler la nouvelle variable $educ = primaire_i + college_i$

- Estimer le modèle RM: $Parite_i = \alpha + \beta_1*urbain_i + \beta_2(educ_i) + \beta_4*catholique_i +...+ \beta_8*age_i +\epsilon_i$



## Exemple 2

- Résultat

$$F^* = \frac{[56164.15 - 55968.90)]/1}{55968.90/(6435)} = 22.45$$


- F(lu) : $F_{1, 6435} = 3.84$ pour $\alpha = 0.05$
- F(lu) : $F_{1, 6435} = 6.63$ pour $\alpha = 0.01$

- Conclusion:

  - Rejet de l'hypothèse nulle: la différence est significative dans les deux cas
  
  
## Exemple 3

$$Parite_i = \alpha + \beta_1*urbain_i + \beta_2*primaire_i + \beta_3*college_i + \beta_4*catholique_i +...+ \beta_8*age_i +\epsilon_i $$ 

- Hypothèse nulle : $H_0 = \beta_2 = 2 , \beta_3 = -5$

- RM: $Parite_i = \alpha + \beta_1*urbain_i + 2*primaire_i - 5*college_i + \beta_4*catholique_i +...+ \beta_8*age_i +\epsilon_i$


- calculer une nouvelle variable dépendante: $Paritenew_i = Parite_i - 2*primaire_i + 5*college_i$
- Estimer le nouvel modele:
- RM: $Paritenew_i = \alpha + \beta_1*urbain_i + \beta_4*catholique_i +...+ \beta_8*age_i +\epsilon_i$
- Calculer la statistique de F et tester l'hypothèse nulle

## Remarque sur F et t test

- Le test t et le test F sont similaires pour le test d'hypothèse sur 1 paramètre
- Deux tests t sont différents d'un test F car les hypothèses nulles sont différentes
- Par exemple: $\beta_1$ et $\beta_2$ peuvent ne pas être significatifs à partir  du test t, mais être conjointement significatifs avec le F test
- SSR(RM) > SSR (UM)
- Le modèle restreint et le modèle sans restriction doivent être basés sur le même échantillon avec le **même nombre d'observations**.


## Degré de liberté

Les degrés de liberté d'une statistique sont le nombre de grandeurs entrant dans le calcul de la statistique moins le nombre de contraintes reliant ces grandeurs. Par exemple, la formule utilisée pour calculer la variance de l'échantillon implique la statistique moyenne de l'échantillon. Cela impose une contrainte sur les données - étant donné la moyenne de l'échantillon, n'importe quel point de données peut être déterminé par les autres (N-1) points de données. Par conséquent, seules des observations non contraintes (N-1) sont disponibles pour estimer la variance de l'échantillon; le degré de liberté de la statistique de variance de l'échantillon est (N-1).



## Voici les résultats tels que reportés par R

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/s7_reg_result1.png)


Violation des hypothèses
=============================================================

## Rappel des hypothèses

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/hypotheses_regression.png)


## 1. Paramètres changeants: Interaction

- Vérifier si le coefficient de régression d'une variable indépendante (X1) varie en fonction des valeurs d'une autre variable indépendante (X2)
- On dit que X2 modère la relation entre X1 et la variable dépendante (Y)

- Plus fréquent entre les variables indépendantes qualitatives et continues
- Moins commun entre variable continue, mais plus facile à interpréter


## Exemple

- Interaction entre deux variables continues
- Salaire = β0 + β1Etudes + β2Expérience + ε

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/interaction1.png)

- Les effets des deux variables indépendantes sont indépendants l'un de l'autre
- β1* = ∂Salaire / Etude (variation de salaire due à une variation unitaire de Education) est indépendant de l'expérience et vice versa

Interaction between two continuous variables
Wage= β0 + β1 Education + β2 Experience + ε
The effect of both IV are independent of each other
β*1 = ∂Wage/∂Education 
is independent of Experience 
and vice versa 

## Exemple

- Cependant, l’effet de l’éducation peut être plus important chez les personnes ayant une expérience plus élevée que chez celles ayant moins d’expérience.
- Les deux droites ne sont pas parallèles

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/interaction2.png)


## Exemple


Salaire = β0 + β1Etude + β2Experience + β3Etude*Experience + ε

- Si β3> 0 ==> une année d’expérience supplémentaire augmente l’effet de l’éducation de β3
- Si β3 <0 ==> une année d’expérience supplémentaire diminue l’effet de l’éducation de β3
- Si β3 = 0 ==> Aucune interaction entre les deux variables


## Exemple

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/interaction3.png)


## Interaction entre deux variables continues

Salaire = β0 + β1 Etude + β2 Experience + β3 Etude * Experience + ε

- ∂Salaire / ∂Etude =?
- ∂Salaire / ∂Etude = β1* + β3*X Experience
- Il est donc clair que l’effet de l’étude sur les salaires dépend de la valeur de l’expérience.
- Avoir le carré d'une variable dans une régression a la même interprétation


## Interaction entre une variable continue et une variable dichotomique (dummy)

- Considérez salaire = β0 + β1 Etude + β2Male + ε
    - Aucun effet d'interaction

- Salaire = β0 + β1 Etude + β2 Homme + β3 Homme * Etude + ε
    - L'effet de l'éducation est différent pour les hommes et les femmes
    - Pour les hommes: salaire = β0 + β1 + (β2 + β3)
    - Pour les femmes: salaire = β0 + β2 Etude
- Sans éducation, la différence entre le salaire des femmes et celui des hommes est β1
- Chaque année supplémentaire d'études, augmente cette différence de β3

## Interaction entre une variable continue et une variable dichotomique (dummy)

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/interaction4.png)


## Interaction entre deux variables nominales

- Prenons l’effet de deux variables nominales sur le salaire:
    - Masculin
    - Secteur d'activités

- Sans interaction:
    - Salaire = β0 + β1 Masculin + β2 Secondaire + β3 Tertiaire + ε
    - Où les références sont Femme (Homme = 0) et Secteur = primaire
    
## Interaction entre deux variables nominales
Avec interaction avec 6 catégories à considérer:

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/interaction5.png)

## Interaction entre deux variables nominales

Il faut bien considérer la référence et exécuter la régression appropriée

- Salaire = β0 + β1 masculin * Prim + β2 masculin * Sec + β3 Fem * Prim + β4 Fem * Sec + β5 Fem * Ter + ε    
- Quelle est la référence?

- Devient complexe à interpréter
- Considérez une variable discrète comme variable continue si cette variable a plusieurs catégories

## 2. Ommission d'une variable importante

## 3. Ajout de variables superflues

## 4. En présence d'hétéroscédasticité

## 5. En présence de non indépendance

## 6. Erreur de mesures

## 7. Multicollinéarité





Tests d'hypothèses 
========================================================

## Introduction

En plus d'estimer les paramètres, les économétriciens souhaitent souvent construire des intervalles de confiance pour leurs estimations et tester des hypothèses concernant les paramètres. Comme dans le cas de l'estimation de paramètres, les tests d'hypothèses consistent à porter un jugement sur des aspects inconnus d'une population donnée sur la base d'informations d'échantillons. Dans le test d'hypothèse, nous voulons savoir si une déclaration sur la population est vraie ou fausse.

## Conception et évaluation d'hypothèses

- Une hypothèse est définie comme une hypothèse sur la population
- Habituellement, l'hypothèse testable consiste à affirmer qu'un paramètre de population donné est égal à une valeur donnée - ou qu'il ne dépasse pas ou ne tombe pas en dessous d'une certaine valeur
- Ceci s'appelle l'hypothèse nulle
- L'hypothèse nulle étant une proposition testable, il doit exister une contre-proposition.
- Cette contre-proposition s'appelle l'hypothèse alternative

## Conception et évaluation d'hypothèses

- Hypothèse nulle (H0)
    - Doit être aussi précis que possible ==> simple
    - La proposition que nous souhaitons réfuter

- L’hypothèse nulle est considérée comme valide à moins que l’évidence ne jette un doute sérieux sur elle.
- L'hypothèse nulle est à "rejeter" ou à "ne pas rejeter"
- La conclusion devrait être "ne pas rejeter" au lieu de "accepter"

## Conception et évaluation d'hypothèses

- Exemple: test d'un nouveau médicament

Un bon exemple de ceci est le test d'un nouveau médicament. Il existe une présomption évidente que le nouveau médicament fera mieux, par exemple en termes de pourcentage moyen de guérison, que l'ancien médicament ou le traitement utilisé, sinon les tests n'auraient aucun sens. Cependant, l'hypothèse nulle pour ce cas sera la proposition selon laquelle le nouveau médicament conduit au même (ou moins) de pourcentage moyen de guérison que l'ancien médicament; L'hypothèse alternative est que le pourcentage moyen est plus élevé pour le nouveau médicament.

## Conception et évaluation d'hypothèses

- Source d'hypothèse
    - Normalement de la théorie
      - Rarement le cas car les théories sont insuffisamment précises et détaillées pour conduire à des hypothèses
      - La théorie spécifie généralement les relations entre les variables
      - L’hypothèse nulle stipule généralement que la relation postulée n’existe pas
  - Recourir à une théorie ad hoc, en utilisant votre bon sens
  - L'échantillon ne doit jamais être utilisé pour formuler l'hypothèse nulle

## Conception et évaluation d'hypothèses

L'établissement de l'hypothèse nulle et de son alternative représente la première étape pour traiter un problème impliquant le test d'hypothèses. La prochaine étape consiste à concevoir un critère qui nous permettrait de décider si l'hypothèse nulle est ou non rejetée sur la base de preuves. Ce critère ou cette règle est en principe le même quel que soit le problème: il définit une statistique de test et une limite permettant de diviser l’espace échantillon en une région de rejet et une région de non-rejet. La statistique de test est simplement une formule nous indiquant comment confronter l'hypothèse nulle à la preuve.

## Critère de test

- Considérez que la moyenne de la variable $X = \mu_0$
  - $H_0: \mu = \mu_0$
  - $H_A: \mu \neq \mu_0$

- Supposer que:
  - X est normalement distribué
  - La variance de X est $\sigma^2$, connue

- La moyenne $\bar{X}$ de l'échantillon suit la loi normale $N(\mu_0, \sigma^2/n)$
  - Si la moyenne $\bar{X}$ est "très différente" de $\mu_0$, rejetez $H_0$
  - Si la moyenne n'est pas "très différente" de $\mu_0$, ne pas rejeter $H_0$

- Qu'est-ce que cela signifie "très différent"

<!--
Les informations que nous recevrons de l'échantillon nous diront évidemment quelque chose sur la moyenne de la population; la question est de savoir comment utiliser cette information.
Nous savons que la moyenne de l'échantillon présente certaines propriétés souhaitables en tant qu'estimateur de la moyenne de la population. Cela suggère que nous pourrions utiliser la moyenne de l'échantillon pour résumer les preuves de l'échantillon concernant la moyenne de la population. Alors un critère évident pour rejeter ou ne pas rejeter l'hypothèse nulle sera le suivant:
Si la valeur de Xbar est très différente de µ0, rejetez l'hypothèse nulle; si ce n'est pas très différent, ne le rejetez pas.
-->

## Critère de test

- Qu'est-ce que cela signifie "très différent"


![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/zone_rejet.png)

<!--
Le critère précédent est clairement inutile pour définir la région critique et la région d'acceptation à moins d'indiquer avec précision les valeurs de Xbar à considérer comme «très différentes» de µ0 et celles qui ne le sont pas. Pour décider cela, nous devons considérer la distribution d'échantillonnage de Xbar. Xbar suit N (0, ∑2 / n). Bien entendu, la distribution normale allant de –infini à + infini, toute valeur de Xbar peut être observée quelle que soit la moyenne de la population. Toutefois, si la moyenne vraie est µ0, les valeurs de Xbar dans les intervalles proches de µ0 apparaîtront avec une probabilité plus grande que celles figurant dans les intervalles (de même longueur) plus éloignés de µ0. Il est donc naturel de considérer comme «très différentes de µ0» les valeurs de Xbar qui - si µ0 est la moyenne vraie - n'apparaissent que très rarement par hasard. Par «très rarement» on entend, du moins pour le moment, «avec une probabilité de 0,01»
Si nous considérons l'hypothèse alternative, cela signifie que si l'hypothèse nulle ne tient pas, la vraie moyenne peut se situer de part et d'autre, les valeurs de Xbar seront beaucoup plus petites ou beaucoup plus grandes.
Puisque nous avons décidé d'appeler un événement très improbable (c'est-à-dire très rare) s'il se produit avec une probabilité de seulement 0,01, cette probabilité doit être partagée également par des valeurs excessivement basses et excessivement élevées de Xbar. En d’autres termes, les limites doivent être définies de telle sorte que la probabilité que xbar soit excessivement faible est de 0,005 et que la probabilité que xbar soit excessivement élevée est également de 0,005.
-->

## Critère de test

Définissons:

- $\mu_L$ la valeur en dessous de laquelle la moyenne $\bar{X}$ serait considérée comme excessivement bas
- $\mu_H$ la valeur au-dessus de laquelle la moyenne $\bar{X}$ serait considérée comme excessivement élevée

Ceci implique que:

- $P(\bar{X} < \mu_L) = 0.005$,
- $P(\bar{X} > \mu_H) = 0.005$ et
- $P(\mu_L < \bar{X} < \mu_H) = 0.99$

## Critère de test

$\bar{X} \sim N(\mu_0, \sigma^2/n)$ ==> $Z = \frac{\bar{X} - \mu_0}{\sqrt{\sigma^2/n}}= \frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \sim N(0, 1)$

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/zone_rejet.png)

## Critère de test

$\bar{X} \sim N(\mu_0, \sigma^2/n)$ ==> $Z = \frac{\bar{X} - \mu_0}{\sqrt{\sigma^2/n}}= \frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \sim N(0, 1)$

![](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/zone_rejet1.png)

## Critère de test: Décision

À partir des tables de distribution normales, nous trouvons:

- $Z_L = -1,96$ et 
- $Z_H = 1,96$

Règle de décision:

- Ne rejeter pas $H_0$ si $-1.96 \le \frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \le 1.96$

## En conclusion

- Préambule : Énoncez l'hypothèse maintenue [exemple: X est normalement distribué avec une variance égale à ...]

## En conclusion

- Préambule : Énoncez l'hypothèse maintenue [exemple: X est normalement distribué avec une variance égale à ...]
- Étape 1: Énoncez l'hypothèse nulle ($H_0$) et l'hypothèse alternative ($H_A$)

## En conclusion

- Préambule : Énoncez l'hypothèse maintenue [exemple: X est normalement distribué avec une variance égale à ...]
- Étape 1: Énoncez l'hypothèse nulle ($H_0$) et l'hypothèse alternative ($H_A$)
- Étape 2: Sélectionner la statistique de test [Exemple: la moyenne $\bar{X}$ basée sur un échantillon de taille ...]

## En conclusion

- Préambule : Énoncez l'hypothèse maintenue [exemple: X est normalement distribué avec une variance égale à ...]
- Étape 1: Énoncez l'hypothèse nulle ($H_0$) et l'hypothèse alternative ($H_A$)
- Étape 2: Sélectionner la statistique de test [Exemple: la moyenne $\bar{X}$ basée sur un échantillon de taille ...]
- Étape 3: Déterminez la distribution de la statistique du test sous l'hypothèse nulle [$\frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \sim N(0, 1)$]

## En conclusion

- Préambule : Énoncez l'hypothèse maintenue [exemple: X est normalement distribué avec une variance égale à ...]
- Étape 1: Énoncez l'hypothèse nulle ($H_0$) et l'hypothèse alternative ($H_A$)
- Étape 2: Sélectionner la statistique de test [Exemple: la moyenne $\bar{X}$ basée sur un échantillon de taille ...]
- Étape 3: Déterminez la distribution de la statistique du test sous l'hypothèse nulle [$\frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \sim N(0, 1)$]
- Étape 4: Choisir le niveau de significance et déterminer la zone d'acceptance et de rejet. [Ne rejeter pas $H_0$ si $-1.96 \le \frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \le 1.96$]

## En conclusion

- Préambule : Énoncez l'hypothèse maintenue [exemple: X est normalement distribué avec une variance égale à ...]
- Étape 1: Énoncez l'hypothèse nulle ($H_0$) et l'hypothèse alternative ($H_A$)
- Étape 2: Sélectionner la statistique de test [Exemple: la moyenne $\bar{X}$ basée sur un échantillon de taille ...]
- Étape 3: Déterminez la distribution de la statistique du test sous l'hypothèse nulle [$\frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \sim N(0, 1)$]
- Étape 4: Choisir le niveau de significance et déterminer la zone d'acceptance et de rejet. [Ne rejeter pas $H_0$ si $-1.96 \le \frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \le 1.96$]
- Étape 5: Sélectionner un échantillon et évaluer le résultat

## En conclusion

- Préambule : Énoncez l'hypothèse maintenue [exemple: X est normalement distribué avec une variance égale à ...]
- Étape 1: Énoncez l'hypothèse nulle ($H_0$) et l'hypothèse alternative ($H_A$)
- Étape 2: Sélectionner la statistique de test [Exemple: la moyenne $\bar{X}$ basée sur un échantillon de taille ...]
- Étape 3: Déterminez la distribution de la statistique du test sous l'hypothèse nulle [$\frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \sim N(0, 1)$]
- Étape 4: Choisir le niveau de significance et déterminer la zone d'acceptance et de rejet. [Ne rejeter pas $H_0$ si $-1.96 \le \frac{(\bar{X} - \mu_0)\sqrt{n}}{\sigma} \le 1.96$]
- Étape 5: Sélectionner un échantillon et évaluer le résultat
- Étape 6: Concluire ["l’échantillon fournit (ne donne pas) des preuves contre l’hypothèse nulle". Pour distinguer les niveaux de signification de 5% et 1%, nous pouvons ajouter le mot **fort** après preuve lorsque vous utilisez le niveau de 1%.]


## Exemple:

EXEMPLE: Des études psychologiques indiquent que, dans la population en général, l'intelligence, mesurée par le QI, se distribue normalement avec une moyenne de 100 et un écart type de 16. Supposons que nous voulions tester si une sous-population donnée, par exemple, toutes les personnes qui utilisent la main gauche (Gauchers) se caractérisent par une moyenne différente. Comme hypothèse maintenue, nous supposons que l’intelligence parmi les gauchers est normalement distribuée avec le même écart type que celui de la population en général, c’est-à-dire 16. Appelons le QI moyen chez les gauchers $\mu$.

## Exemple

Un échantillon de 400 observations est prélevé. Le QI est de 99.

- Étape 1: Hypothèse maintenue: $\bar{X} \sim N(\mu_0 = 100, \sigma^2 = 162)$
- Étape 2: $H_0: \mu = 100$, $H_A \neq 100$
- Étape 3: Sous $H_0$: $Z = \frac{(\bar{X}-100)*\sqrt{4000}}{16} \sim N(0,1)$
- Étape 4: Décision: ne pas rejeter si $-1.96 \le Z \le 1.96$
    - Niveau de signification à 5%

RÉPONSE

- Calculer les statistiques de test: $Z = \frac{(99-100)*\sqrt{4000}}{16} = -1.25$

- Décision: ne pas rejeter $H_0$ car il est compris entre -1.96 et 1.96


## Type d'erreur

Chaque conclusion sur le test d'hypothèse peut englober deux types d'erreur:

- Erreur de type I: rejetter $H_0$ alors qu’elle est vraie (erreur $\alpha$)

- Erreur de type II: Ne pas rejeter $H_0$ alors qu’il est faux (erreur $\beta$)

![Erreurs de type I et de type II](/Users/visseho/OneDrive - UQAM/Cours/Images_cours/erreur.png)


